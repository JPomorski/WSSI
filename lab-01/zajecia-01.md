## Zadanie 1

Które z następujących zadań wymagają w Twojej opinii inteligencji od człowieka:
- streszczanie tekstu,
- układanie rozkładu jazdy transportu miejskiego
- programowanie (pisanie programów komputerowych)
- testowanie oprogramowania
- komponowanie muzyki
- symboliczne obliczanie pochodnych funkcji
- symboliczne całkowanie funkcji
- kierowanie samochodem

## Zadanie 2

Które z następujących problemów można uznać za mieszczące się w zakresie sztucznej
inteligencji:

- streszczanie tekstu
- tłumaczenie tekstu
- klasyfikacja tekstu do kategorii tematycznych
- odpowiadanie na proste pytania zadawane w języku naturalnym
- rozwiązywanie układów równań
- rozwiązywanie układów równań liniowych
- symboliczne obliczanie pochodnych
- symboliczne całkowanie

## Zadanie 3

Które z poniższych rodzajów komunikacyjnego zachowania człowieka mogą być
obecnie skutecznie imitowane przez sztuczne systemy (odpowiednio oprogramowane
maszyny):

- rozmowa towarzyska
- odpowiadanie na pytania klientów w telefonicznej infolinii
- odpowiadanie na pytania klientów w internetowej infolinii

## Zadanie 4

Głównie użyłem cleverbota i swoich doświadczeń z ChatGPT.

# 1)
Boty przygotowane na test Turinga próbują w dosyć naturalny sposób brnąć przez rozmowę, nawet jeśli nie znają odpowiedzi.
Boty asystenci bardzo łatwo się gubią i albo zaczynają się powtarzać, albo kompletnie zmieniają tor rozmowy.

# 2, 3)
Opowiadanie żartów to tragedia. O ile np. Chat GPT sobie jakoś radzi (choć jego żarty nie wykazują zbyt dużego potencjału komediowego), tak boty mniej złożone albo odmawiają opowiedzenia żartu (ponieważ nie wchodzi to w zakres ich kompetencji), albo kompletnie zmieniają temat. Podobnie wygląda sprawa cytowania:
-- Do you know any good Tolkien quotes?
-- No not really.

I to by było na tyle...

Słowa-klucze są w stanie wymusić jakąś konkretną odpowiedź, zależy tylko jakie. Ogólne pojęcia dotyczące świata realnego działają w tym wypadku najlepiej.
Duże ilości pytań i powracanie do poprzednich wypowiedzi dla większości botów stanowi jednak problem. Chat GPT jest do tego stworzony więc umie sobie poradzić.
Pozostałe boty najczęściej odnoszą się jedynie do ostatniej wysłanej wiadomości. Powoduje to często zapętlenie i powtarzanie w kółko jednej kwestii.

Generalnie boty-asystenci dosyć dobrze radzą sobie z odgrywaniem swojej roli. Są przystosowane do otrzymywania dużej ilości pytań, i jeśli są one w odpowiedniej tematyce to potrafią sobie z nimi poradzić. Wypowiedzi te jednak nie zawsze są płynne i czasem wyraźnie widać że pisze je bot.
Drugą sprawą jest to, że takiego bota łatwo wywieść w pole zadając mu pytania spoza zakresu jego kompetencji. Najczęściej odpowiada wymijająco albo wymaga zadania innego pytania.

# 5)
Bardzo łatwo wnerwiłem cleverbota: po otrzymaniu "I think you need to study" odpowiedział "I think you need to mind your own business."


